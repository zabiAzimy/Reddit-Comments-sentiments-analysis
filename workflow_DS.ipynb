{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b4e16cd-f911-4667-b8f2-e4e3b11b3458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the required libraries\n",
    "import pandas as pd\n",
    "import praw\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf7a90a",
   "metadata": {},
   "source": [
    "#### Data acquisition\n",
    "\n",
    "I am using Reddit API to collect data. The data is concerned with comments in different reddit subcommunities. Here I have considered the 'politics' subcommunity. In here I am searching for the post titles containing the word 'Trump' or 'Harris'.\n",
    "\n",
    "The titles that contain one of these words will be taken and all the comments for them will be added to a Python list.\n",
    "Comments for the titles containing 'Trump' and 'Harris' will be stored in separate lists. \n",
    "\n",
    "I am acquiring and preparing these data for sentiment analysis task. So to find out the overall public sentiment towards Trump and Harris in Reddit space. Although by no means it can be near to a true speculation about the topic, but to follow the standard procedure of working on a machine learning task.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Ongoing challenges\n",
    "- When running the cells that sends request to Reddit API endpoint, due to large amount of data available, it takes several minutes (10-12) to complete.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18ef476a-ff83-43be-806c-dca6a4bdb94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titles containing Trump: 406\n",
      "Titles containing Harris: 88\n",
      "There are total 46000 comments for Trump\n",
      "There are total 6037 comments for Harris\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize Reddit API connection\n",
    "reddit = praw.Reddit(\n",
    "    client_id='tZwMe0a2cneHp6qZz_x09w',\n",
    "    client_secret='Hp-RZTXgWHFSayjB5177ZyKRPfVpQw',\n",
    "    user_agent='Mean_Stuff7937'\n",
    ")\n",
    "\n",
    "# Lists to store the titles and comments\n",
    "politics_titles_trump = []\n",
    "politics_titles_harris = []\n",
    "\n",
    "# List contains comments about posts related to Trump\n",
    "comments_trump = []\n",
    "\n",
    "# List contains comments about posts related to Harris\n",
    "comments_harris = []\n",
    "\n",
    "# Access the 'politics' subreddit\n",
    "subreddit = reddit.subreddit('politics')\n",
    "\n",
    "# Function to safely handle comments for a given post\n",
    "def handle_comments(post, title_list, comment_list):\n",
    "    title_list.append(post.title)\n",
    "    post.comments.replace_more(limit=0)  # Collapse \"load more comments\"\n",
    "    for comment in post.comments.list():\n",
    "        comment_list.append(comment.body)\n",
    "\n",
    "# Limit to a certain number of posts to avoid overwhelming the API\n",
    "for post in subreddit.hot(limit=None):  # Fetch top 100 posts\n",
    "    try:\n",
    "        title_lower = post.title.lower()  # Make title lowercase for case-insensitive match\n",
    "\n",
    "        # Check if 'trump' is in the title\n",
    "        if 'trump' in title_lower:\n",
    "            handle_comments(post, politics_titles_trump, comments_trump)\n",
    "\n",
    "        # Check if 'harris' is in the title\n",
    "        elif 'harris' in title_lower:\n",
    "            handle_comments(post, politics_titles_harris, comments_harris)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred with post: {post.title}, error: {e}\")\n",
    "        time.sleep(2)  # Delay to avoid rate-limiting issues\n",
    "\n",
    "# Print the count of titles containing 'Trump' and 'Harris'\n",
    "print(f\"Titles containing Trump: {len(politics_titles_trump)}\")\n",
    "print(f\"Titles containing Harris: {len(politics_titles_harris)}\")\n",
    "print(f\"There are total {len(comments_trump)} comments for Trump\")\n",
    "print(f\"There are total {len(comments_harris)} comments for Harris\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9919688",
   "metadata": {},
   "source": [
    "#### Creating data frame for titles for each, Trump and Harris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37f301d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_politics_comments_trump' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# save the dataframe into a csv file\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df_politics_titles_trump\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf_politics_titles_trump.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mdf_politics_comments_trump\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_politics_comments_trump' is not defined"
     ]
    }
   ],
   "source": [
    "# convert the above lists into dataframes\n",
    "df_politics_titles_trump = pd.DataFrame(politics_titles_trump, columns=['politics_titles_Trump'])\n",
    "\n",
    "# save the dataframe into a csv file\n",
    "df_politics_titles_trump.to_csv(\"df_politics_titles_trump.csv\")\n",
    "\n",
    "df_politics_comments_trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8d0b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert it to a dataframe\n",
    "df_politics_titles_harris = pd.DataFrame(politics_titles_harris, columns=['politics_titles_harris'])\n",
    "\n",
    "# save it to a csv file\n",
    "df_politics_titles_harris.to_csv(\"df_politics_titles_harris.csv\", index=False)\n",
    "\n",
    "df_politics_titles_harris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f1bf99",
   "metadata": {},
   "source": [
    "#### Creating data frames of comments for each, Trump and Harris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382ebb9b-c8b5-4446-b829-c716eb57fcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe for comments\n",
    "df_politics_comments_trump = pd.DataFrame(comments_trump, columns=[\"Comments_trump\"])\n",
    "\n",
    "# save the dataframe into a csv file\n",
    "df_politics_comments_trump.to_csv(\"politics_comments_trump.csv\", index=False)\n",
    "\n",
    "df_politics_comments_trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e0a85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data frame for the comments\n",
    "df_politics_comments_harris = pd.DataFrame(comments_harris, columns=['Comments_harris'])\n",
    "\n",
    "# save it to a csv file\n",
    "df_politics_comments_harris.to_csv(\"politics_comments_harris.csv\")\n",
    "\n",
    "df_politics_comments_harris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d00c2d",
   "metadata": {},
   "source": [
    "### Data exploration\n",
    "Here we explore our datasets to get a better idea about them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3a3b56-61e1-409e-a990-532f8f86e937",
   "metadata": {},
   "source": [
    "#### This cell will be for my note taking\n",
    "\n",
    "- Explore all the subreddit communities\n",
    "- we will look and search for comments related to a specific word, such as 'Donald Trump'\n",
    "- We will compare the sentiments in different subreddit communitites\n",
    "- The previous step will give us some idea how overall public sentiments are towards 'Donald Trump'\n",
    "- The subreddit communities identified so far:\n",
    "  - News\n",
    "  - Politics\n",
    "  - sports\n",
    "  - World News\n",
    "  - Funny\n",
    "      \n",
    "\n",
    "\n",
    "#### How to proceed?\n",
    "I will gather comments from subreddit communities and will do some exploration.\n",
    "\n",
    "\n",
    "## Sentiment Analysis using VADER\n",
    "\n",
    "I use VADER here to label the datasets, as labelling them manually is not feasible at the moment.\n",
    "\n",
    "We used VADER, a rule-based sentiment analysis tool for social media text (Hutto & Gilbert, 2014), to analyze the polarity of comments in Reddit.\n",
    "\n",
    "### References\n",
    "Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc689b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to get sentiment label using VADER\n",
    "def get_sentiment_label(comment):\n",
    "    sentiment_dict = analyzer.polarity_scores(comment)\n",
    "    compound_score = sentiment_dict['compound']\n",
    "    \n",
    "    # Assign sentiment label based on compound score\n",
    "    if compound_score >= 0.05:\n",
    "        return 'positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Assuming you have a DataFrame of Reddit comments (replace with your collected data)\n",
    "df_sentiments_trump = pd.DataFrame({\n",
    "    'Comment': df_politics_comments_trump['Comments_trump']\n",
    "})\n",
    "\n",
    "# Apply VADER to auto-label comments\n",
    "df_sentiments_trump['Sentiment'] = df_sentiments_trump['Comment'].apply(get_sentiment_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea9e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_sentiments_trump)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40af3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame of Reddit comments (replace with your collected data)\n",
    "df_sentiments_harris = pd.DataFrame({\n",
    "    'Comment': df_politics_comments_harris['Comments_harris']\n",
    "})\n",
    "\n",
    "# Apply VADER to auto-label comments\n",
    "df_sentiments_harris['Sentiment'] = df_sentiments_harris['Comment'].apply(get_sentiment_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c67439",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiments_harris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085904a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of sentiments in the dataset for Harris\n",
    "sentiment_counts_harris = df_sentiments_harris['Sentiment'].value_counts()\n",
    "print(sentiment_counts_harris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd820ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of sentiments in the dataset for Trump\n",
    "sentiment_counts_trump = df_sentiments_trump['Sentiment'].value_counts()\n",
    "print(sentiment_counts_trump)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d2c36a",
   "metadata": {},
   "source": [
    "#### Some exploratory steps\n",
    "\n",
    "According to the labels assigned to each comment in the dataset, we check the proportion of each class of sentiment (i.e positive, negative and neutral)\n",
    "\n",
    "As it can be seen below, from the comments collected, there are almost equal proportion of negative and positive for Trump while the proportion of negative sentiments for Harris is lower."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361c7e2e",
   "metadata": {},
   "source": [
    "### What proportion of comments are related to Harris vs Trump\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab80a9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the counts of comments for Harris vs Trump \n",
    "trump_comments_count = len(df_politics_comments_trump)\n",
    "\n",
    "harris_comments_count = len(df_politics_comments_harris)\n",
    "\n",
    "print(f\"No of comments related to Trump: {trump_comments_count}\")\n",
    "print(f\"No of comments related to Harris: {harris_comments_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1f3282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for plotting\n",
    "labels = ['Trump', 'Harris']\n",
    "comment_counts = [trump_comments_count, harris_comments_count]\n",
    "\n",
    "# Create a bar chart\n",
    "plt.figure(figsize=(8, 6))  # Adjusts the size of the plot\n",
    "bars = plt.bar(labels, comment_counts, color=['#E50000', 'blue'])\n",
    "\n",
    "# Add labels, title, and grid\n",
    "plt.title('Comparison of Comments for Trump vs Harris', fontsize=16)\n",
    "plt.xlabel('Person', fontsize=14)\n",
    "plt.ylabel('Number of Comments', fontsize=14)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Annotate the bars with the actual counts\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 50, int(yval), ha='center', fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500febc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts_harris = sentiment_counts_harris.sum()\n",
    "\n",
    "# Calculate proportions for each sentiment\n",
    "sentiment_proportions_harris = sentiment_counts_harris / total_counts_harris\n",
    "\n",
    "# Create a bar plot for proportions\n",
    "plt.figure(figsize=(7,5))\n",
    "sentiment_proportions_harris.plot(kind='bar', color=['#15B01A', '#E50000', 'gray'])\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Sentiment Distribution (Proportions)')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Proportion')\n",
    "\n",
    "# Set x-axis ticks for better readability\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "print(sentiment_proportions_harris)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eee6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts_trump = sentiment_counts_trump.sum()\n",
    "\n",
    "# Calculate proportions for each sentiment\n",
    "sentiment_proportions_trump = sentiment_counts_trump / total_counts_trump\n",
    "\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(7, 5))\n",
    "sentiment_proportions_trump.plot(kind='bar', color=['#15B01A', '#E50000', 'gray'])\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Sentiment Distribution (Proportions)')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Proportion')\n",
    "\n",
    "# Set x-axis ticks for better readability\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "print(sentiment_proportions_trump)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b37757",
   "metadata": {},
   "source": [
    "### Merging of both the datasets\n",
    "\n",
    "I want to merge both the comments datasets with their corresponding sentiments as labels.\n",
    "I am preparing this merged dataset for sentiment classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c572f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiments_harris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd263400",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiments_trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcc6e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiments_harris.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3dfbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append df_sentiments_trump to df_sentiments_harris\n",
    "df_merged = pd.concat([df_sentiments_harris, df_sentiments_trump], ignore_index=True)\n",
    "\n",
    "# Display the shape of the merged dataframe\n",
    "print(df_merged.shape)\n",
    "\n",
    "# Optional: Display the first few rows of the merged dataframe to verify\n",
    "print(df_merged.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734a9579",
   "metadata": {},
   "source": [
    "## Clean the data a bit\n",
    "\n",
    "Basic cleaning processes in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eca247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Strip leading and trailing whitespaces from the 'Comment' column\n",
    "df_merged['Comment'] = df_merged['Comment'].str.strip()\n",
    "\n",
    "# Step 2: Remove rows where 'Comment' is empty or too short (e.g., less than 5 characters)\n",
    "df_merged = df_merged[df_merged['Comment'].str.len() > 5]\n",
    "\n",
    "# Step 3: Drop duplicate rows if any exist\n",
    "df_merged = df_merged.drop_duplicates()\n",
    "\n",
    "# Step 4: Standardize the 'Sentiment' column to be lowercase\n",
    "df_merged['Sentiment'] = df_merged['Sentiment'].str.lower()\n",
    "\n",
    "# Step 5: Check and drop any rows with missing values\n",
    "df_merged = df_merged.dropna()\n",
    "\n",
    "# Optional: Reset index after cleaning\n",
    "df_merged = df_merged.reset_index(drop=True)\n",
    "\n",
    "# Display the cleaned DataFrame shape and first few rows\n",
    "print(df_merged.shape)\n",
    "print(df_merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c26d645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Preprocess the data\n",
    "# Convert 'Sentiment' to numeric form (e.g., 'positive' = 1, 'negative' = 0, 'neutral' = 2)\n",
    "df_merged['Sentiment'] = df_merged['Sentiment'].map({'positive': 1, 'negative': 0, 'neutral': 2})\n",
    "\n",
    "# Check if there are any NaN values after encoding\n",
    "df_merged = df_merged.dropna()\n",
    "\n",
    "# 2. Split the data into training and testing sets\n",
    "X = df_merged['Comment']  # Feature: the text comments\n",
    "y = df_merged['Sentiment']  # Target: sentiment labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Convert text data into numerical form using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# 4. Train a Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# 5. Make predictions and evaluate the model\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# 6. Evaluate the performance of the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5b005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report dictionary for precision, recall, and f1-score\n",
    "report = {\n",
    "    'Sentiment': ['Negative', 'Positive', 'Neutral'],\n",
    "    'Precision': [0.82, 0.82, 0.76],\n",
    "    'Recall': [0.77, 0.80, 0.85],\n",
    "    'F1-Score': [0.79, 0.81, 0.80]\n",
    "}\n",
    "\n",
    "# Create a DataFrame for easy plotting\n",
    "df_report = pd.DataFrame(report)\n",
    "\n",
    "# Plot precision, recall, and f1-score\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "df_report.set_index('Sentiment').plot(kind='bar', ax=ax)\n",
    "\n",
    "plt.title('Precision, Recall, and F1-Score for Each Sentiment Class', fontsize=16)\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0.5, 1.0)\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(loc='lower right', fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Confusion Matrix Visualization\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Labels for the confusion matrix\n",
    "labels = ['Negative', 'Positive', 'Neutral']\n",
    "\n",
    "# Plot the confusion matrix using seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "\n",
    "plt.title('Confusion Matrix for Sentiment Analysis', fontsize=16)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409a768b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Binarize the labels for One-vs-Rest strategy (0 = negative, 1 = positive, 2 = neutral)\n",
    "y_bin = label_binarize(y, classes=[0, 1, 2])\n",
    "n_classes = y_bin.shape[1]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train_bin, y_test_bin = train_test_split(X, y_bin, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the text into TF-IDF features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# 2. Train a One-vs-Rest Logistic Regression model\n",
    "classifier = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
    "classifier.fit(X_train_tfidf, y_train_bin)\n",
    "\n",
    "# 3. Predict probabilities for the test set\n",
    "y_score = classifier.decision_function(X_test_tfidf)\n",
    "\n",
    "# 4. Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot the ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "colors = ['blue', 'green', 'red']\n",
    "labels = ['Negative', 'Positive', 'Neutral']\n",
    "\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2, \n",
    "             label=f'ROC curve for {labels[i]} (area = {roc_auc[i]:0.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)  # Diagonal line for random guessing\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=14)\n",
    "plt.ylabel('True Positive Rate', fontsize=14)\n",
    "plt.title('ROC Curves for Sentiment Analysis (One-vs-Rest)', fontsize=16)\n",
    "plt.legend(loc='lower right', fontsize=12)\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
