{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4b4e16cd-f911-4667-b8f2-e4e3b11b3458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import praw\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ef476a-ff83-43be-806c-dca6a4bdb94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Reddit API connection\n",
    "reddit = praw.Reddit(\n",
    "    client_id='tZwMe0a2cneHp6qZz_x09w',\n",
    "    client_secret='Hp-RZTXgWHFSayjB5177ZyKRPfVpQw',\n",
    "    user_agent='Mean_Stuff7937'\n",
    ")\n",
    "\n",
    "# Test connection by accessing a subreddit\n",
    "subreddit = reddit.subreddit('news')\n",
    "for post in subreddit.hot(limit=None):\n",
    "    print(post.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5518291-316d-49f4-b95c-bfb5fc40e83f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to store comments\n",
    "comments_list = []\n",
    "\n",
    "# Access the 'worldnews' subreddit\n",
    "subreddit = reddit.subreddit('news')\n",
    "\n",
    "# Loop through the hot posts in the subreddit\n",
    "for post in subreddit.hot(limit=None):\n",
    "    # Check if the title contains 'Trump' or 'Harris'\n",
    "    if 'Trump' in post.title or 'Harris' in post.title:\n",
    "        print(f\"Title: {post.title}\")  # To confirm matching titles\n",
    "        # Replace the placeholder comment with the actual code to extract comments\n",
    "        post.comments.replace_more(limit=0)  # This handles \"load more comments\" issues\n",
    "        for comment in post.comments.list():\n",
    "            comments_list.append(comment.body)  # Add each comment body to the list\n",
    "\n",
    "# Create a DataFrame from the list of comments\n",
    "df_comments_trump_harris = pd.DataFrame(comments_list, columns=['Comment'])\n",
    "\n",
    "# Save the DataFrame to a CSV file (optional)\n",
    "df_comments_trump_harris.to_csv('filtered_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3a6a972b-9501-4667-b5e2-189713916029",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“The public’s confidence in the integrity of our judicial system demands a sentencing hearing that is entirely focused on the verdict of the jury and the weighing of aggravating and mitigating factors free from distraction or distortion”\\n\\nFuck Merchan. If he really believed this, he wouldn’t let the upcoming election affect his timeline and decisions. He needs to uphold the law. Period.'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments_trump_harris.shape\n",
    "# Show the first few rows of the DataFrame\n",
    "df_comments_trump_harris['Comment'][66]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b8700a6a-ef31-48bb-b19c-46d70bcbf575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Putin claims Russia will support Harris in US elections\n",
      "                                             Comment\n",
      "0  I'm sure this isn't related to the DOJ investi...\n",
      "1  The world seriously operates on impulsive chil...\n",
      "2       They also said they wouldn’t invade Ukraine.\n",
      "3            Michael Scott level reverse psychology.\n",
      "4  How stupid do they think Americans ar... Oh wa...\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store comments\n",
    "comments_list_case_insensitive = []\n",
    "\n",
    "# Access the 'worldnews' subreddit\n",
    "subreddit = reddit.subreddit('worldnews')\n",
    "\n",
    "# Loop through the hot posts in the subreddit\n",
    "for post in subreddit.hot(limit=None):\n",
    "    # Convert title to lowercase for case-insensitive matching\n",
    "    title_lower = post.title.lower()\n",
    "    \n",
    "    # Check if the title contains 'trump' or 'harris' (case-insensitive)\n",
    "    if 'trump' in title_lower or 'harris' in title_lower:\n",
    "        print(f\"Title: {post.title}\")  # To confirm matching titles\n",
    "        # Replace the placeholder comment with the actual code to extract comments\n",
    "        post.comments.replace_more(limit=0)  # This handles \"load more comments\" issues\n",
    "        for comment in post.comments.list():\n",
    "            comments_list_case_insensitive.append(comment.body)  # Add each comment body to the list\n",
    "\n",
    "# Create a DataFrame from the list of comments\n",
    "df_comments_insensitive = pd.DataFrame(comments_list_case_insensitive, columns=['Comment'])\n",
    "\n",
    "# Save the DataFrame to a CSV file (optional)\n",
    "df_comments_insensitive.to_csv('filtered_comments_insensitive.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87bd1db-10c2-4aa9-8cf3-8165698caeb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show the first few rows of the DataFrame\n",
    "df_comments_insensitive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3a3b56-61e1-409e-a990-532f8f86e937",
   "metadata": {},
   "source": [
    "#### This cell will be for my note taking\n",
    "\n",
    "- Explore all the subreddit communities\n",
    "- we will look and search for comments related to a specific word, such as 'Donald Trump'\n",
    "- We will compare the sentiments in different subreddit communitites\n",
    "- The previous step will give us some idea how overall public sentiments are towards 'Donald Trump'\n",
    "- The subreddit communities identified so far:\n",
    "  - News\n",
    "  - Politics\n",
    "  - sports\n",
    "  - World News\n",
    "  - Funny\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0d4143c-5344-4ca3-aa95-1282628fff53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Post Title\n",
      "0  What free things online should everyone take  ...\n",
      "1  What “long song” (6+ minutes) is worth every m...\n",
      "2    What show failed because someone left the show?\n",
      "3  HR people of Reddit: What's the most NSFW/WTF ...\n",
      "4                    What have you lost interest in?\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store post titles\n",
    "titles = []\n",
    "\n",
    "# Loop through the hot posts and store the titles\n",
    "for post in subreddit.hot(limit=None):\n",
    "    titles.append(post.title)\n",
    "\n",
    "# Create a DataFrame from the titles list\n",
    "df = pd.DataFrame(titles, columns=['Post Title'])\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Optionally, save the DataFrame to a CSV file\n",
    "df.to_csv('askreddit_titles.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "acdfa060-913b-4064-a6df-e8f6ec5375f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(898, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06a2630-bc7c-476e-85e3-ab8302aaa7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store post titles and their corresponding comments\n",
    "post_titles = []\n",
    "post_comments = []\n",
    "\n",
    "# Loop through the hot posts and retrieve comments\n",
    "for post in subreddit.hot(limit=10):  # Use limit=None to retrieve all posts\n",
    "    post_titles.append(post.title)\n",
    "    \n",
    "    # Get all the comments in the post\n",
    "    post.comments.replace_more(limit=None)  # To load all comments\n",
    "    comments = []\n",
    "    \n",
    "    for comment in post.comments.list():\n",
    "        comments.append(comment.body)\n",
    "    \n",
    "    # Join all comments into a single string and add it to the list\n",
    "    post_comments.append(\" | \".join(comments))\n",
    "\n",
    "# Create a DataFrame from the titles and comments list\n",
    "df = pd.DataFrame({\n",
    "    'Post Title': post_titles,\n",
    "    'Comments': post_comments\n",
    "})\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Optionally, save the DataFrame to a CSV file\n",
    "df.to_csv('askreddit_posts_and_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9bba076c-2afb-4a38-89a3-b96d99eef8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Comment Sentiment\n",
      "0                                 This is fantastic!  positive\n",
      "1  Judge Merchan made a political decision. and r...   neutral\n",
      "2  This is utter bullshit. Two tiered justice is ...  positive\n",
      "3                    Absolutely horrible experience.  negative\n",
      "4  The judge is more worried about optics than ju...  positive\n"
     ]
    }
   ],
   "source": [
    "# Initialize VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to get sentiment label using VADER\n",
    "def get_sentiment_label(comment):\n",
    "    sentiment_dict = analyzer.polarity_scores(comment)\n",
    "    compound_score = sentiment_dict['compound']\n",
    "    \n",
    "    # Assign sentiment label based on compound score\n",
    "    if compound_score >= 0.05:\n",
    "        return 'positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Assuming you have a DataFrame of Reddit comments (replace with your collected data)\n",
    "df = pd.DataFrame({\n",
    "    'Comment': [\n",
    "        'This is fantastic!', \n",
    "        'Judge Merchan made a political decision. and remember, Judge Chutkan recently ruled that the election is not relevant. Two very different perspectives.', \n",
    "        'This is utter bullshit. Two tiered justice is full on display once again. Our legal system has become complete trash from bottom to top',\n",
    "        'Absolutely horrible experience.',\n",
    "        'The judge is more worried about optics than justice. Time to step down.',\n",
    "        'The public’s confidence in the integrity of our judicial system demands a sentencing hearing that is entirely focused on the verdict of the jury and the weighing of aggravating and mitigating factors free from distraction or distortion”\\n\\nFuck Merchan. If he really believed this, he wouldn’t let the upcoming election affect his timeline and decisions. He needs to uphold the law. Period.'\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Apply VADER to auto-label comments\n",
    "df['Sentiment'] = df['Comment'].apply(get_sentiment_label)\n",
    "\n",
    "# Now you have a labeled dataset\n",
    "print(df)\n",
    "\n",
    "# You can save this auto-labeled dataset for future use\n",
    "df.to_csv('auto_labeled_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c97df5-955d-463c-a62d-839aaa97b553",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
